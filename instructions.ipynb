{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e89050f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Python refresher workshop 1\n",
    "\n",
    "During this workshop (spanning four weeks), we will build a few different syllabification systems, i.e. models which can split words into sequences of syllables:\n",
    "\n",
    "```\n",
    "aɪ s l ə n d ə  ->  aɪ s . l ə n . d ə\n",
    "```\n",
    "\n",
    "In this first meeting, we will focus on data processing and evaluation. We'll also implement a  baseline syllabification algorithm. A baseline model is essentially a simple model that acts as a reference in a machine learning project. Our baseline will simply chunk the input into segments of two characters (with an optional single character segment at the end):\n",
    "\n",
    "```\n",
    "aɪ s l ə n d ə  ->  aɪ s . l ə . n d . ə\n",
    "t͡ʃ aɪ n ə t aʊ n z   t͡ʃ aɪ . n ə . t aʊ . n z\n",
    "```\n",
    "\n",
    "This is obviously not a great result. For example, `n d` is a pretty weird syllable.  However, this will give us a baseline performance that we can compare to when we start developing more complex syllabification systems. Any reasonable syllabifier needs to be able to beat this simple baseline.\n",
    "\n",
    "The idea is to work on the exercises in pairs or small teams (though you can also work individually if you prefer). For people with no python experience, it's a good idea to team up with someone who is a bit more experienced.  \n",
    "\n",
    "The following python lectures on Canvas can be useful:\n",
    "\n",
    "* [String handling](https://canvas.ubc.ca/courses/65386/files/9375671?module_item_id=2255551)\n",
    "* [Loops](https://canvas.ubc.ca/courses/65386/files/9375677?module_item_id=2255559)\n",
    "* [Reading from files](https://canvas.ubc.ca/courses/65386/files/9375679?module_item_id=2255563)\n",
    "\n",
    "These materials should take you pretty far, but googling can also be useful. You are also very welcome to ask each other, Miikka and Roger for help. \n",
    "\n",
    "There are hints in the notebook which you can view by clicking on the hint. It's probably a good idea to try first and look at the hint if you need additional help.\n",
    "\n",
    "If you feel that you have no idea how to get started, let Miikka and Roger know. We can discuss the exercises together.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d989a47",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 0. Preparation\n",
    "\n",
    "If you're using [Google Colab](https://colab.research.google.com/?utm_source=scs-index), first upload this notebook (under the \"Upload\" tab). Once you're in the Colab, navigate to the \"Files\" panel to the left, create a new folder called \"data\" (by right-clicking and selecting \"New folder\"), and then upload the train, dev, and test files into the newly-created data folder (by right-clicking on the \"data\" folder and hitting \"Upload\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cbbf2c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 0. Preparation\n",
    "\n",
    "If you're using [Google Colab](https://colab.research.google.com/?utm_source=scs-index), first upload this notebook (under the \"Upload\" tab). Once you're in the Colab, navigate to the \"Files\" panel to the left, create a new folder called \"data\" (by right-clicking and selecting \"New folder\"), and then upload the train, dev, and test files into the newly-created data folder (by right-clicking on the \"data\" folder and hitting \"Upload\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58a837",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Reading the data\n",
    "\n",
    "We are given data files in the following format:\n",
    "\n",
    "```\n",
    "'d          d                    d\n",
    "Bulls       b ʊ l z              b ʊ l z\n",
    "Chinatowns  t͡ʃ aɪ n ə t aʊ n z   t͡ʃ aɪ . n ə . t aʊ n z\n",
    "I'll        aɪ l                 aɪ l\n",
    "Icelander   aɪ s l ə n d ə       aɪ s . l ə n . d ə\n",
    "```\n",
    "\n",
    "This is a [TSV](https://www.loc.gov/preservation/digital/formats/fdd/fdd000533.shtml) file which contains three tabulator-separated (```'\\t'```) columns:\n",
    "\n",
    "1. Orthographic word\n",
    "2. IPA transcription\n",
    "3. Syllabified IPA transcription\n",
    "\n",
    "All IPA symbols are separated by single spaces and syllable boundaries are marked by a `.`\n",
    "\n",
    "We recommend first writing a function `read_line()`, which takes a line (i.e. string consisting of three tab-separated fields) as input, e.g.:\n",
    "\n",
    "```\n",
    "\"Chinatowns  t͡ʃ aɪ n ə t aʊ n z   t͡ʃ aɪ . n ə . t aʊ n z\"\n",
    "```\n",
    "\n",
    "and converts it into a Python dictionary having the following format:\n",
    "\n",
    "```\n",
    "{\"orth\": \"Chinatowns\",\n",
    " \"ipa\": [\"t͡ʃ\", \"aɪ\", \"n\", \"ə\", \"t\", \"aʊ\", \"n\", \"z\"],\n",
    " \"syll\": [([\"t͡ʃ\", \"aɪ\"], 0, 2), ([\"n\", \"ə\"], 2, 4), ([\"t\", \"aʊ\", \"n\", \"z\"], 4, 8)]}\n",
    "```\n",
    "\n",
    "Apart from `syll`, the fields are pretty self-explanatory. In the `syll` field, we've got a list of tuples representing each syllable, its start index and end index (which is 1 + the index of its final character). E.g. the syllable `\"n\", \"ə\"`, in the example above, starts at index 2 and ends at index 4:\n",
    "\n",
    "```\n",
    "IPA:   \"t͡ʃ\", \"aɪ\", \"n\", \"ə\", \"t\", \"aʊ\", \"n\", \"z\"\n",
    "index:  0     1     2    3    4    5     6    7\n",
    "```\n",
    "\n",
    "After implementing the function `read_line()`, you can implement a function `read_data()`, which reads a file into a list of dictionaries. \n",
    "\n",
    "Use `read_data()` to read the training, development and test data and store the result in variables `train_data`, `dev_data` and `test_data`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11dae7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the first hint</summary>\n",
    "    To create the \"syll\" list, you need to loop through the syllabified IPA transcription and track the index of each IPA symbol (There is a function that allows you to get index while looping). Note that because of the presence of the syllable boundary \".\", the raw index of an IPA symbol needs to be modified to get the correct index.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f583bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the second hint</summary>\n",
    "    You'll need to initialize two variables before looping through the transcription. One variable is used to track the start index for each variable, while the other variable is used to track how many \".\" you have encountered. The latter variable can then be used to derive the correct start and end indices.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046de4f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the third hint</summary>\n",
    "    Here is the skeleton for one possible way to solve the problem:\n",
    "    <code>\n",
    "    for index, symbol in IPAs:\n",
    "        case 1: if symbol is \".\" (i.e., you reach the end of a syllable)\n",
    "            add the current syllable to syll list\n",
    "            update the two variables that track start index and # of \".\" seen\n",
    "        case 2: if we reach the end of IPAs (last syllable)\n",
    "            add the last syllable to syll list\n",
    "        case 3: \"else\" condition\n",
    "            add the symbol to the current syllable\n",
    "    </code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81565a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def read_line(line):\n",
    "    orth, ipa, ipa_syl = line.strip().split(sep='\\t')\n",
    "    ipa = ipa.split(sep=' ')\n",
    "    \n",
    "    ipa_syl = ipa_syl.split(sep=' ')\n",
    "    syll = []\n",
    "    offset = 0  # offset to correct indices due to '.'\n",
    "    start = 0  # start index\n",
    "    ipas = []  # string representation of syllable\n",
    "    \n",
    "    for i, symbol in enumerate(ipa_syl):\n",
    "        if symbol == '.':\n",
    "            syll.append((ipas, start, i + offset))\n",
    "            start = i + offset\n",
    "            offset -= 1  # offset = offset - 1\n",
    "            ipas = []\n",
    "        elif i == len(ipa_syl) - 1:  # reach the end\n",
    "            ipas.append(symbol)\n",
    "            syll.append((ipas, start, i + offset + 1))\n",
    "        else:  # see a normal IPA\n",
    "            ipas.append(symbol)\n",
    "    \n",
    "    return {'orth': orth, 'ipa': ipa, 'syll': syll}\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    words = []\n",
    "    with open(path, mode='r') as f:\n",
    "        for line in f:\n",
    "            word_dict = read_line(line)\n",
    "            words.append(word_dict)\n",
    "    return words\n",
    "\n",
    "train = read_data('./data/train.tsv')\n",
    "test = read_data('./data/test.tsv')\n",
    "dev = read_data('./data/dev.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b1f44",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Baseline\n",
    "\n",
    "Today we will implement a very trivial baseline syllabifier function `baseline()`. It contains no phonological insight. Instead, it simply chops the input word into \"syllables\" of length 2. E.g. given the input:\n",
    "\n",
    "```\n",
    "t͡ʃ aɪ n ə t aʊ n z\n",
    "```\n",
    "\n",
    "the baseline function would syllabify:\n",
    "\n",
    "```\n",
    "t͡ʃ aɪ . n ə . t aʊ . n z\n",
    "```\n",
    "\n",
    "**Note:** If the input contains an odd number of IPA symbols, then the final symbol should constitute a singleton syllable. E.g, `aɪ s l ə n d ə -> aɪ s . l ə . n d . ə`. \n",
    "\n",
    "Given the input string:\n",
    "\n",
    "```\n",
    "[\"t͡ʃ\", \"aɪ\", \"n\", \"ə\", \"t\", \"aʊ\", \"n\", \"z\"]\n",
    "```\n",
    "\n",
    "`baseline()` should return:\n",
    "\n",
    "```\n",
    "[([\"t͡ʃ\", \"aɪ\"], 0, 2), ([\"n\", \"ə\"], 2, 4), ([\"t\", \"aʊ\"], 4, 6), ([\"n\", \"z\"], 6, 8)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef0c11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the first hint</summary>\n",
    "    You can use the index value to see if you need to insert a syllable boundary \".\".\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb250f26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the second hint</summary>\n",
    "    More specifically, whether to insert a boundary is determined by whether the current index is odd or even. You can use the remainder of a 2-division to see if the index is odd or even. The modulo operator <code>%</code> will be handy here. Note that you do NOT need to insert a syllable boundary \".\" after the last syllable.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f40e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def get_syll_indices(syllabified_ipa_list):\n",
    "    syll = []\n",
    "    offset = 0  # offset to correct indices due to '.'\n",
    "    start = 0  # start index\n",
    "    ipas = []  # string representation of syllable\n",
    "    \n",
    "    for i, symbol in enumerate(syllabified_ipa_list):\n",
    "        if symbol == '.':\n",
    "            syll.append((ipas, start, i + offset))\n",
    "            start = i + offset\n",
    "            offset -= 1  # offset = offset - 1\n",
    "            ipas = []\n",
    "        elif i == len(syllabified_ipa_list) - 1:  # reach the end\n",
    "            ipas.append(symbol)\n",
    "            syll.append((ipas, start, i + offset + 1))\n",
    "        else:  # see a normal IPA\n",
    "            ipas.append(symbol)\n",
    "    return syll\n",
    "\n",
    "def baseline(ipa_list):\n",
    "    syllabified = []\n",
    "    # [t͡ʃ, aɪ, n, ə, t, aʊ, n, z] -> [t͡ʃ, aɪ, ., n, ə, ., t, aʊ, ., n, z]\n",
    "    for i, symbol in enumerate(ipa_list):\n",
    "        if i % 2 == 1 and i != len(ipa_list) - 1:  # add '.' if the index is odd and not the last one\n",
    "            syllabified.append(symbol)\n",
    "            syllabified.append('.')\n",
    "        else:\n",
    "            syllabified.append(symbol)\n",
    "\n",
    "    # [t͡ʃ, aɪ, ., n, ə, ., t, aʊ, ., n, z] -> pass this through part of the code we write in Q1\n",
    "    return get_syll_indices(syllabified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71bbccf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Evaluation\n",
    "\n",
    "We will evaluate the performance of the baseline system using [F1-score](https://deepai.org/machine-learning-glossary-and-terms/f-score).\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)\n",
    "\n",
    "E.g. given gold standard syllabified strings:\n",
    "\n",
    "```\n",
    "[([\"t͡ʃ\", \"aɪ\"], 0, 2), ([\"n\", \"ə\"], 2, 4), ([\"t\", \"aʊ\", \"n\", \"z\"], 4, 8)]\n",
    "[([\"aɪ\", \"s\"], 0, 2), ([\"l\", \"ə\", \"n\"], 2, 5), ([\"d\", \"ə\"], 5, 7), ([\"s\"], 7, 8)]\n",
    "```\n",
    "\n",
    "and a baseline system output:\n",
    "\n",
    "```\n",
    "[([\"t͡ʃ\", \"aɪ\"], 0, 2), ([\"n\", \"ə\"], 2, 4), ([\"t\", \"aʊ\"], 4, 6), ([\"n\", \"z\"], 6, 8)]\n",
    "[([\"aɪ\", \"s\"], 0, 2), ([\"l\", \"ə\"], 2, 4), ([\"n\", \"d\"], 4, 6), ([\"ə\", \"s\"], 7, 8)]\n",
    "```\n",
    "\n",
    "we have 3 true positives: \n",
    "\n",
    "```\n",
    "[\"t͡ʃ\", \"aɪ\"], [\"n\", \"ə\"], [\"aɪ\", \"s\"] \n",
    "```\n",
    "and 5 false positives:\n",
    "\n",
    "```\n",
    "[\"t\", \"aʊ\"], [\"n\", \"z\"], [\"l\", \"ə\"], [\"n\", \"d\"], [\"ə\", \"s\"]\n",
    "``` \n",
    "\n",
    "and 4 false negatives: \n",
    "\n",
    "```\n",
    "[\"t\", \"aʊ\", \"n\", \"z\"], [\"l\", \"ə\", \"n\"], [\"d\", \"ə\"], [\"s\"]\n",
    "``` \n",
    "\n",
    "This results in precision: \n",
    "\n",
    "$$P = \\frac{\\text{true pos}}{(\\text{true pos} + \\text{false pos})} = 3/8$$ \n",
    "\n",
    "and recall: \n",
    "\n",
    "$$R = \\frac{\\text{true pos}}{(\\text{true pos} + \\text{false neg})} = 3/7$$ \n",
    "\n",
    "giving F1-score: \n",
    "\n",
    "$$F_1 = 2 * P * R / (P + R) = 0.4 $$\n",
    "\n",
    "You should implement a function `evaluate()` which takes two lists as input: (1) a list of system output syllabified strings, and (2) a list of gold standard syllabified strings. The function then computes the F1-score and returns it. \n",
    "\n",
    "**Note:** You should sum up the true positive, false positive and false negative scores over the entire dataset before computing F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1057c08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the first hint</summary>\n",
    "    Note that you need to compare the corresponding gold standard and system output. That is, you shouldn't collect the syllables from all gold standards into a giant gold set, collect the syllables from all system outputs into a giant system set, and calculate precision and recall use these two sets.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213b9e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the second hint</summary>\n",
    "    The set operations like intersection and difference will be useful here to calculate true positive, false positive, and false negative.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65606ef0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def evaluate(gold, system):\n",
    "    tp = 0  # true positive\n",
    "    fp = 0  # false positive\n",
    "    fn = 0  # false negative\n",
    "\n",
    "    for g, s in zip(gold, system):\n",
    "        g = [(tuple(syll[0]), syll[1], syll[2]) for syll in g]\n",
    "        s = [(tuple(syll[0]), syll[1], syll[2]) for syll in s]\n",
    "\n",
    "        tp += len(set(g) & set(s))\n",
    "        fp += len(set(s) - set(g))\n",
    "        fn += len(set(g) - set(s))\n",
    "\n",
    "    pre = tp / (tp + fp)  # precision\n",
    "    rec = tp / (tp + fn)  # recall\n",
    "    return 2 * pre * rec / (pre + rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f6c2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Python refresher workshop 2\n",
    "\n",
    "This week, we'll start by implementing a slightly less trivial syllabification algorithm than `baseline()`. The function `cv_syll()` assigns syllable boundaries after every vowel. This will allow it to syllabify many English words correctly, e.g. *Phoenicia* `f ɪ n ɪ ʃ ə` as `f ɪ . n ɪ . ʃ ə`. \n",
    "\n",
    "There are, however, a few problems with this approach. For example, we run the risk of creating syllables without nuclei at the end of words endining in a consonant. E.g. `n z` in `t͡ʃ aɪ . n ə . t aʊ . n z`. Therefore, as a special case, the function will assign all symbols following the last vowel in the word into the coda of the last syllable. Given this modification, the function will return the correct syllabification `t͡ʃ aɪ . n ə . t aʊ n z`.  \n",
    "\n",
    "### 1. Evaluating the baseline\n",
    "\n",
    "Start by running the `baseline()` syllabificiation algorithm on the development set and use `evaluate()` to figure out the F1-score of the baseline syllabification method. The F1-score should be around 26%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052a4e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the first hint</summary>\n",
    "    Note that you need to convert your dev list to the correct format before passing it to evaluate(). For instance, change\n",
    "    \n",
    "    [\n",
    "        {'orth': 'abrade',\n",
    "         'ipa': ['ə', 'b', 'ɹ', 'eɪ', 'd'],\n",
    "         'syll': [(['ə'], 0, 1), (['b', 'ɹ', 'eɪ', 'd'], 1, 5)]},\n",
    "        {'orth': 'abraded',\n",
    "         'ipa': ['ə', 'b', 'ɹ', 'eɪ', 'd', 'ɪ', 'd'],\n",
    "         'syll': [(['ə'], 0, 1), (['b', 'ɹ', 'eɪ'], 1, 4), (['d', 'ɪ', 'd'], 4, 7)]},\n",
    "        {'orth': 'abrasion',\n",
    "         'ipa': ['ə', 'b', 'ɹ', 'eɪ', 'ʒ', 'n̩'],\n",
    "         'syll': [(['ə'], 0, 1), (['b', 'ɹ', 'eɪ'], 1, 4), (['ʒ', 'n̩'], 4, 6)]}\n",
    "    ]\n",
    "    \n",
    "to\n",
    "    \n",
    "    [\n",
    "        [(['ə'], 0, 1), (['b', 'ɹ', 'eɪ', 'd'], 1, 5)],\n",
    "        [(['ə'], 0, 1), (['b', 'ɹ', 'eɪ'], 1, 4), (['d', 'ɪ', 'd'], 4, 7)],\n",
    "        [(['ə'], 0, 1), (['b', 'ɹ', 'eɪ'], 1, 4), (['ʒ', 'n̩'], 4, 6)]\n",
    "    ]\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c026ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "dev_syll = [d['syll'] for d in dev]\n",
    "\n",
    "baseline_syll = []\n",
    "with open('./data/dev.tsv', mode='r') as f:\n",
    "    for line in f:\n",
    "        _, ipa, _ = line.strip().split(sep='\\t')\n",
    "        word_dict = baseline(ipa.split(sep=' '))\n",
    "        baseline_syll.append(word_dict)\n",
    "\n",
    "evaluate(dev_syll, baseline_syll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c7db7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Consonant and vowel sets\n",
    "\n",
    "You should then form two sets `CONS` and `VOWEL`, which contain all consonants and vowels in the training set (if you can't upload the training set to Colab, it's also fine to use the development set). You need to:\n",
    "\n",
    "1. Form a set `IPAS` of all IPA symbols that occur in the train/development set and print the set.\n",
    "1. Then, manually create two sets `CONS` and `VOWEL` based on the inventory in `IPAS`. \n",
    "\n",
    "**Note!** There are a few syllabic consonants in the data set. These are marked by a small diacritic (`n̩ ŋ̩ m̩ l̩`). You need to think about whether to include these in your consonant or vowel set (or possibly both). Examine the development data, to figure out what makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816312f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "IPAS = set()\n",
    "\n",
    "with open('data/train.tsv') as f:\n",
    "    for line in f:\n",
    "        orth, trans, syll = line.strip().split(sep='\\t')\n",
    "        IPAS.update(trans.split(sep=' '))\n",
    "\n",
    "with open('data/dev.tsv') as f:\n",
    "    for line in f:\n",
    "        orth, trans, syll = line.strip().split(sep='\\t')\n",
    "        IPAS.update(trans.split(sep=' '))\n",
    "\n",
    "CONS = {'f', 'ʃ', 'j', 'l', 'ɹ', 'h', 'b', 'v', 'w', 'd',\n",
    "        'ð', 'k', 'x', 's', 'ʒ', 'θ', 't͡ʃ', 't', 'n', 'p',\n",
    "        'd͡ʒ', 'ŋ', 'm', 'ɡ', 'z'}\n",
    "VOWEL = {'ʌ', 'm̩', 'n̩', 'ɒ̃ː', 'l̩', 'ɪə', 'ŋ̩', 'ɒ', 'ə', 'aʊ',\n",
    "         'ɪ', 'iː', 'æ̃ː', 'ɑː', 'æ', 'uː', 'ɛ', 'ɜː', 'ʊ', 'əʊ',\n",
    "         'ɔː', 'aɪ', 'ɔɪ', 'eɪ', 'ʊə', 'ɑ̃ː', 'ɛə'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2a1dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. `cv_syll()`\n",
    "\n",
    "Now we can start creating the `cv_syll()` function. The function takes a list of IPA symbols as input. For example,\n",
    "\n",
    "```\n",
    "[\"t͡ʃ\", \"aɪ\", \"n\", \"ə\", \"t\", \"aʊ\", \"n\", \"z\"]\n",
    "```\n",
    "\n",
    "It returns the syllabified string in the same format as `baseline()`:\n",
    "\n",
    "```\n",
    "[([\"t͡ʃ\", \"aɪ\"], 0, 2), ([\"n\", \"ə\"], 2, 4), ([\"t\", \"aʊ\", \"n\", \"s\"], 4, 8)]\n",
    "```\n",
    "\n",
    "where each element is a 3-tuple containing a string representation of a syllable like `[\"t͡ʃ\", \"aɪ\"]` and its start and end index in the IPA string.\n",
    "\n",
    "You should implement `cv_syll()` by looping through the input string. While looping, we need to keep track of two variables: \n",
    "\n",
    "* `index` the current index in the IPA string\n",
    "* `start` the start index of the syllable which we are currently creating.\n",
    "\n",
    "The index `start` will be initialized to 0 at the start of the process. Whenever you are done with a syllable, you will need to update the value of `start`.\n",
    "\n",
    "Below you see an example of how `start` and `index` change when processing `[\"t͡ʃ\", \"aɪ\", \"n\", \"ə\"]`:\n",
    "\n",
    "```\n",
    "   index = 0, start = 0 # Start of the process \n",
    "t͡ʃ index = 0, start = 0 \n",
    "aɪ index = 1, start = 2 # Create the syllable ([\"t͡ʃ\", \"aɪ\"], 0, 2) and update start\n",
    "n  index = 2, start = 2\n",
    "ə  index = 3, start = 4 # Create the syllable ([\"n\", \"ə\"], 2, 4) and update start\n",
    "                        # End of input. We return [([\"t͡ʃ\", \"aɪ\"], 0, 2), \n",
    "                        #                          ([\"n\", \"ə\"], 2, 4)].\n",
    "```\n",
    "\n",
    "Whenever you encounter a vowel (i.e. a symbol which is in your `VOWEL` set), you should create a new syllable boundary. The only exception is when this is the last vowel in the word. We recommend that you first implement a simple version of `cv_syll()`, which creates a boundary after every vowel. When you are sure that the simple version works, you can improve it by handling the word-final syllable correctly.    \n",
    "\n",
    "When you're done with `cv_syll()`, please run it on the development set and evaluate against the gold standard annotations. You should get F1-score around 59%.\n",
    "\n",
    "**Note!** Make sure that you return all the syllables under all conditions. You should make sure that the final syllable is returned both when the final vowel is followed by some consonants and when it is the last character of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c60bd8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the first hint</summary>\n",
    "    You can <code>index</code> for free by using the <code>enumerate()</code> function:\n",
    "    \n",
    "    for index, symbol in enumerate(ipas):\n",
    "        ...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234535de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the second hint</summary>\n",
    "    You also need to deal with cases where there is just one consonant. For example,\n",
    "    \n",
    "    ['d']\n",
    "    \n",
    "    or\n",
    "    \n",
    "    ['z']    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed2326",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# sylls = []    <-- list to store all syllables\n",
    "# current_syll = []\n",
    "# start = 0\n",
    "\n",
    "#        ɑː t ɪ f ɪ ʃ ə l ɪ\n",
    "# index: 0  1 2 3 4 5 6 7 8\n",
    "\n",
    "# ɑː\n",
    "# start: 0\n",
    "# index: 0\n",
    "# current_syll: [ɑː]\n",
    "# sylls: [([ɑː], 0, 1)] = [([ɑː], start, index+1)]\n",
    "# curret_syll = []\n",
    "# start = index + 1 = 1\n",
    "\n",
    "# t:\n",
    "# start: 1\n",
    "# index: 1\n",
    "# current_syll: [t]\n",
    "\n",
    "# ɪ\n",
    "# start: 1\n",
    "# index: 2\n",
    "# current_syll: [t ɪ]\n",
    "# sylls: [([ɑː], 0, 1), ([t ɪ], 1, 3)] # [([t ɪ], start, index+1)]\n",
    "# curret_syll = []\n",
    "# start = index + 1 = 3\n",
    "\n",
    "# ...\n",
    "\n",
    "# ɪ\n",
    "# start: 7\n",
    "# index: 9\n",
    "# current_syll: [l ɪ]\n",
    "# add to sylls\n",
    "# curret_syll = []\n",
    "# start = index + 1 = 3\n",
    "\n",
    "\n",
    "\n",
    "def cv_syll(ipas):\n",
    "    sylls = []\n",
    "    current_syll = []\n",
    "\n",
    "    start = 0\n",
    "    for index, symbol in enumerate(ipas):\n",
    "        current_syll.append(symbol)\n",
    "        \n",
    "        if symbol in VOWEL:\n",
    "            # the end of the current syllable, append it!\n",
    "            sylls.append((current_syll, start, index + 1))\n",
    "\n",
    "            start = index + 1\n",
    "            current_syll = []\n",
    "\n",
    "        if index == len(ipas) - 1:  # end of ipa list\n",
    "\n",
    "            # handle cases like [z] or [d]\n",
    "            if sylls == []:\n",
    "                sylls.append(([], start, index + 1))\n",
    "\n",
    "            # ə ɹ ɛ s t\n",
    "            # sylls = [[ə], [ɹ, ɛ]]\n",
    "            # current_syll = [[s, t]]\n",
    "            # take out the last syllable [ɹ, ɛ], combine it with current_syll\n",
    "\n",
    "            sylls[-1] = (sylls[-1][0] + current_syll,\n",
    "                         sylls[-1][1],  # original start\n",
    "                         index + 1)\n",
    "\n",
    "    return sylls\n",
    "\n",
    "\n",
    "dev_syll = [d['syll'] for d in dev]\n",
    "\n",
    "baseline_syll = []\n",
    "with open('./data/dev.tsv', mode='r') as f:\n",
    "    for line in f:\n",
    "        _, ipa, _ = line.strip().split(sep='\\t')\n",
    "        word_dict = cv_syll(ipa.split(sep=' '))\n",
    "        baseline_syll.append(word_dict)\n",
    "\n",
    "evaluate(dev_syll, baseline_syll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00baeb5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert cv_syll(['ɑː', 't', 'ɪ', 'f', 'ɪ', 'ʃ', 'ə', 'l', 'ɪ']) == [(['ɑː'], 0, 1), (['t', 'ɪ'], 1, 3), (['f', 'ɪ'], 3, 5), (['ʃ', 'ə'], 5, 7), (['l', 'ɪ'], 7, 9)]\n",
    "assert cv_syll(['t͡ʃ', 'aɪ', 'n', 'ə', 't', 'aʊ', 'n', 'z']) == [(['t͡ʃ', 'aɪ'], 0, 2), (['n', 'ə'], 2, 4), (['t', 'aʊ', 'n', 'z'], 4, 8)]\n",
    "assert cv_syll(['z']) == [(['z'], 0, 1)]\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98175b8e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Improving the syllabifier\n",
    "\n",
    "The `cv_syll()` function already handles most English syllable boundaries correctly, however, there are a few points of improvement. E.g. the function isn't horribly good at handling consonant clusters in words like `æ d v ə n t` which is incorrectly syllabified as `æ . d v ə n t` instead of the correct `æ d . v ə n t`. \n",
    "\n",
    "Please investigate the performance of `cv_syll()` on the development data. Compare against gold standard syllabifications, finding errors and try to figure out why the syllabification fails. Then write an improved version `clever_syll()` which fixes some of these errors. \n",
    "\n",
    "We suggest solving one problem at a time and iteratively improving `clever_syll`. Throughout the engineering process, it's a good idea to make sure that your modifications result in improved performance by using the `evaluate()` function.\n",
    "\n",
    "You should able get F1-score > 60%, possibly closer to 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a652aa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2be9c7",
   "metadata": {},
   "source": [
    "## Python refresher workshop 3\n",
    "\n",
    "For this week, we'll be tracking some statistics about the segmental environments where syllable boundaries (or lack thereof) occur. These numbers will be useful for the tasks we're going to perform next week.\n",
    "\n",
    "### 1. Extracting unigram segmental environments\n",
    "\n",
    "The first type of statistics we'll extract is the previous and subsequent segments of a syllable boundary or a \"non-boundary\". For instance, given the syllabified word `ə . d æ p . t ə`, there are two (non-edge) syllable boundaries in the environments of `ə_d` and `p_t`, and there are three non-boundaries in the environments of `d_æ`, `æ_p`, and `t_ə`. Your task here is to build two counter dictionaries to track the frequency of different segmental environemtns associated with the boundaries and non-boundaries from the words in the training set. Your dictionary counters should have the following structure:\n",
    "\n",
    "```\n",
    "uni_bndry_cntr = {\n",
    "    ('ə', '_', 'd'): 507,  # the number represents the # of times this environment occurs with a syllable boundary\n",
    "    ('p', '_', 't'): 340,\n",
    "    ...\n",
    "}\n",
    "\n",
    "uni_non_bndry_cntr = {\n",
    "    ('d', '_', 'æ'): 213,  # the number represents the # of times this environment occurs without a syllable boundary\n",
    "    ('æ', '_', 'p'): 380,\n",
    "    ('t', '_', 'ə'): 4160,\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9012a21",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the first hint</summary>\n",
    "    Using a pre-packaged <code>Counter</code> object can save you some time. Observe the following example:\n",
    "    \n",
    "    from collections import Counter\n",
    "    \n",
    "    \n",
    "    example_list = ['a', 'a', 'b', 'b', 'b', 'c']\n",
    "    example_counter = Counter()\n",
    "    \n",
    "    for l in example_list:\n",
    "        example_counter[l] += 1\n",
    "    \n",
    "Your <code>example_counter</code> will then look like this:\n",
    "    \n",
    "    {'a': 2, 'b': 3, 'c': 1}\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fa8d2",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"font-weight: bold;\">Click here to see the second hint</summary>\n",
    "    You'll notice that you need to find a way to identify \"non-boundaries\". One way to do this is to explicitly insert them into your transcription first, so when you loop through the transcription, you know whether you run into a boundary or non-boundary. For example, given <code>ə . d æ p . t ə</code>, you can first turn it into <code>ə . d | æ | p . t | ə</code>, so when you loop through it, you know you encounter a syllable boundary is it's a <code>.</code> and a non-boundary if it's a <code>|</code>.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert uni_bndry_cntr[('ə', '_', 'd')] == 507\n",
    "assert uni_non_bndry_cntr[('ə', '_', 'd')] == 891\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ef9f7",
   "metadata": {},
   "source": [
    "### 2. Extracting bigram segmental environments\n",
    "\n",
    "This task is similar to what you just did, but we expand our window to include the previous 2 and the following 2 segments of a syllable boundary/non-boundary. You'll notice that you need to pad each word at the begining and end before you extract environemts. For instance, with the word `ə . d æ p . t ə`, you need to first pad the word to `# ə . d æ p . t ə #`. Then for boundaries, you'll have `#ə_dæ` and `æp_tə`, and for non-boundaries, you'll have `əd_æp`, `dæ_pt`, and `pt_ə#`. Again, create two counters to track the number of different environments associated with both boundaries types from the words in the training set:\n",
    "\n",
    "```\n",
    "bi_bndry_cntr = {\n",
    "    ('#', 'ə', '_', 'd', 'æ'): 6,\n",
    "    ('æ', 'p', '_', 't', 'ə'): 8,\n",
    "    ...\n",
    "}\n",
    "\n",
    "bi_non_bndry_cntr = {\n",
    "    ('ə', 'd', '_', 'æ', 'p'): 6,\n",
    "    ('d', 'æ', '_', 'p', 't'): 8,\n",
    "    ('p', 't', '_', 'ə', '#'): 11,\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bda85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f81272",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bi_bndry_cntr[('æ', 'p', '_', 't', 'ə')] == 8\n",
    "assert bi_non_bndry_cntr[('ə', 'd', '_', 'æ', 'p')] == 6\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa8115",
   "metadata": {},
   "source": [
    "### 3. Extracting unigram and bigram CV environments\n",
    "\n",
    "This task involves abstraction over the first and second task. That is, instead of having an environment for each unique segmental combination, your environment simply tells you whether the preceding and following segments are a consonant `C` or a vowel `V`. For instance, given the syllabified word `ə . d æ p . t ə`, there are two syllable boundaries in the unigram environments of `V_C` (from `ə_d`) and `C_C` (from `p_t`), and there are three non-boundaries in the unigram environments of `C_V` (from `d_æ` and `t_ə`) and `V_C` (from `æ_p`). You should perform the same transformation for different bigram environments by, for example, turning `pt_ə#` into `CC_V#`.\n",
    "\n",
    "Create four dictionary counters---`uni_bndry_cv_cntr`, `uni_non_bndry_cv_cntr`, `bi_bndry_cv_cntr`, and `bi_non_bndry_cv_cntr`---that store the frequency information of different environments. For example, your `bi_non_bndry_cv_cntr` should look like:\n",
    "\n",
    "```\n",
    "bi_non_bndry_cv_cntr = {\n",
    "    ('#', 'V', '_', 'C', '#'): 113,\n",
    "    ('#', 'C', '_', 'V', 'C'): 47872,\n",
    "    ('C', 'V', '_', 'C', '#'): 39376,\n",
    "    ('#', 'C', '_', 'C', 'V'): 13721,\n",
    "    ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd6e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5fbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert uni_bndry_cv_cntr[('C', '_', 'C')] == 35728\n",
    "assert uni_non_bndry_cv_cntr[('C', '_', 'C')] == 57891    \n",
    "assert bi_non_bndry_cv_cntr[('V', 'C', '_', 'V', 'C')] == 61265\n",
    "assert bi_bndry_cv_cntr[('V', 'C', '_', 'C', 'V')] == 27337\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15adee7",
   "metadata": {},
   "source": [
    "### 4. Turning frequencies into probabilities\n",
    "\n",
    "Your last task for this week is to turn counts/frequencies in all of your dictionary counters into probabilities. Consider the following toy example:\n",
    "\n",
    "```\n",
    "example_cntr = {\n",
    "    'a': 2,\n",
    "    'b': 5,\n",
    "    'c': 8,\n",
    "    'd': 5\n",
    "}\n",
    "```\n",
    "\n",
    "We can then turn the count of each key-value pair into probability by dividing the count by the sum of all values. So, for example, `a` now has a probability of $2 / (2 + 5 + 8 + 5) = 0.1$. The final dictionary of probabilities is then:\n",
    "\n",
    "```\n",
    "example_prob = {\n",
    "    'a': 0.1,\n",
    "    'b': 0.25,\n",
    "    'c': 0.4,\n",
    "    'd': 0.25\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# you can call your freq dict uni_bndry_prob, uni_non_bndry_prob, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0.003 < uni_bndry_prob[('ə', '_', 'd')] < 0.004\n",
    "assert 0.002 < uni_non_bndry_prob[('ə', '_', 'd')] < 0.003\n",
    "\n",
    "print('Success!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
